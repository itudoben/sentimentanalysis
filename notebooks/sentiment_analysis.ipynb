{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Analysis of a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample text'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_list = [\"is\", \"a\", \"this\", \"...\"] \n",
    "def _remove_noise(input_text):\n",
    "    words = input_text.split() \n",
    "    noise_free_words = [word for word in words if word not in noise_list] \n",
    "    noise_free_text = \" \".join(noise_free_words) \n",
    "    return noise_free_text\n",
    "\n",
    "_remove_noise(\"this is a sample text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base path for the ACL IMDB data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the reviews into data frames.\n",
    "base_path = \"/Users/hujol/Projects/advanced_analytics_spark/data/aclImdb/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the files into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Python system path to find our modules.\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import our modules.\n",
    "import file_loader as fl\n",
    "\n",
    "# Add the file to SparkContext for the executor to find it.\n",
    "sc.addPyFile('../src/file_loader.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in a parquet file.\n",
    "file_pqt, df = fl.load_data(base_path, 252, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README                     \u001b[34maclImdb_250_raw.parquet\u001b[m\u001b[m\n",
      "aclImdb_100000.csv         \u001b[34maclImdb_251_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34maclImdb_100000_raw.parquet\u001b[m\u001b[m \u001b[34maclImdb_252_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34maclImdb_10000_raw.parquet\u001b[m\u001b[m  \u001b[34maclImdb_300_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34maclImdb_1000_raw.parquet\u001b[m\u001b[m   \u001b[34maclImdb_301_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34maclImdb_100_raw.parquet\u001b[m\u001b[m    \u001b[34maclImdb_50000_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34maclImdb_20000_raw.parquet\u001b[m\u001b[m  imdb.vocab\n",
      "\u001b[34maclImdb_2000_raw.parquet\u001b[m\u001b[m   imdbEr.txt\n",
      "\u001b[34maclImdb_200_raw.parquet\u001b[m\u001b[m    \u001b[34mtest\u001b[m\u001b[m\n",
      "\u001b[34maclImdb_210_raw.parquet\u001b[m\u001b[m    \u001b[34mtrain\u001b[m\u001b[m\n",
      "\u001b[34maclImdb_211_raw.parquet\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls {base_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store as CVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ttl = 250\n",
    "\n",
    "# Define the CSV file.\n",
    "file_csv = os.path.join(base_path, (\"aclImdb_%s.csv\" % ttl))\n",
    "\n",
    "# Get the data as Pandas data frame.\n",
    "pdf = df.toPandas()\n",
    "\n",
    "# Re index to shuffle the data before saving it.\n",
    "pdf = pdf.reindex(np.random.permutation(pdf.index))\n",
    "pdf.to_csv(file_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the CSV file for checking data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasettype</th>\n",
       "      <th>filename</th>\n",
       "      <th>datetimecreated</th>\n",
       "      <th>reviewid</th>\n",
       "      <th>reviewpolarity</th>\n",
       "      <th>reviewrating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>9487_1.txt</td>\n",
       "      <td>20181025T053838Z</td>\n",
       "      <td>9487</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I have seen this movie and I did not care for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>4604_4.txt</td>\n",
       "      <td>20181025T053838Z</td>\n",
       "      <td>4604</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>In Los Angeles, the alcoholic and lazy Hank Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  datasettype    filename   datetimecreated  reviewid  reviewpolarity  \\\n",
       "1        test  9487_1.txt  20181025T053838Z      9487               0   \n",
       "2        test  4604_4.txt  20181025T053838Z      4604               0   \n",
       "\n",
       "   reviewrating                                               text  \n",
       "1             1  I have seen this movie and I did not care for ...  \n",
       "2             4  In Los Angeles, the alcoholic and lazy Hank Ch...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ttl = 250\n",
    "\n",
    "# Define the CSV file.\n",
    "file_csv = os.path.join(base_path, (\"aclImdb_%s.csv\" % ttl))\n",
    "\n",
    "pdf_read = pd.read_csv(file_csv, encoding='utf-8')\n",
    "pdf_read[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = spark.createDataFrame(pdf_read)\n",
    "df_csv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data from the parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+----------------+--------+--------------+------------+--------------------+\n",
      "|datasettype|    filename| datetimecreated|reviewid|reviewpolarity|reviewrating|                text|\n",
      "+-----------+------------+----------------+--------+--------------+------------+--------------------+\n",
      "|       test| 10813_7.txt|20181025T053838Z|   10813|             1|           7|The movie takes p...|\n",
      "|       test|11813_10.txt|20181025T053838Z|   11813|             1|          10|The Cure is a fan...|\n",
      "|       test|   835_8.txt|20181025T053838Z|     835|             1|           8|The original Fema...|\n",
      "|       test|  4245_8.txt|20181025T053838Z|    4245|             1|           8|remember back whe...|\n",
      "|       test| 11856_7.txt|20181025T053838Z|   11856|             1|           7|Sophisticated sex...|\n",
      "|       test|  6133_8.txt|20181025T053838Z|    6133|             1|           8|I stumbled upon t...|\n",
      "|       test| 10167_9.txt|20181025T053838Z|   10167|             1|           9|A film that tends...|\n",
      "|       test|  903_10.txt|20181025T053838Z|     903|             1|          10|This is a well do...|\n",
      "|       test|  1466_8.txt|20181025T053838Z|    1466|             1|           8|A strange relatio...|\n",
      "|       test|  6176_8.txt|20181025T053838Z|    6176|             1|           8|This is a brillia...|\n",
      "|       test| 5124_10.txt|20181025T053838Z|    5124|             1|          10|i read the book b...|\n",
      "|       test| 2807_10.txt|20181025T053838Z|    2807|             1|          10|I played Sam (the...|\n",
      "|       test|  4038_9.txt|20181025T053838Z|    4038|             1|           9|\"Snow Queen\" is b...|\n",
      "|       test| 10961_9.txt|20181025T053838Z|   10961|             1|           9|Watching John Cas...|\n",
      "|       test|  2835_7.txt|20181025T053838Z|    2835|             1|           7|This is a luminou...|\n",
      "|       test| 7695_10.txt|20181025T053838Z|    7695|             1|          10|I was @ 13 yrs of...|\n",
      "|       test|  9919_9.txt|20181025T053838Z|    9919|             1|           9|Title: Opera (198...|\n",
      "|       test| 12091_8.txt|20181025T053838Z|   12091|             1|           8|'Crossing the Bri...|\n",
      "|       test| 6644_10.txt|20181025T053838Z|    6644|             1|          10|A gruelling watch...|\n",
      "|       test| 9491_10.txt|20181025T053838Z|    9491|             1|          10|I bought my first...|\n",
      "+-----------+------------+----------------+--------+--------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the parquet file is good.\n",
    "df_pqt = spark.read.parquet(file_pqt)\n",
    "\n",
    "# As needed.\n",
    "# df_pqt = df_pqt.drop('words')\n",
    "\n",
    "# Showing some observations (entries).\n",
    "df_pqt.persist()\n",
    "df_pqt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pqt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the text to clean HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the secrets] of the universe. <br /><br />Unfortunately, \n",
      "the secrets of the universe Unfortunately \n"
     ]
    }
   ],
   "source": [
    "# Let's test our cleaning functions.\n",
    "a_text = 'the secrets] of the universe. <br /><br />Unfortunately, '\n",
    "print(a_text)\n",
    "print(fl.clean_html(a_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(text='The movie takes place during the year 1940 and the French are about to loose the war.<br /><br />The movie includes all genres: comedy, romantic, murder and history. It is probable the historical part may be not as probable as the rest.<br /><br />It is not, however, a big laugh movie but the occasional large smile!', textclean='The movie takes place during the year 1940 and the French are about to loose the war It is not however a big laugh movie but the occasional large smile ')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the parquet data frame.\n",
    "df_pqt = fl.transform_html_clean(df_pqt, 'textclean')\n",
    "df_pqt.select('text', 'textclean').take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "words = ['write','writer','writing','writers']\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word}: {ps.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer.lemmatize('dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Features Extractor Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "df_pqt = df_pqt.drop('words')\n",
    "            \n",
    "tokenizer = Tokenizer(inputCol=\"textclean\", outputCol=\"words\")\n",
    "df_pqt = tokenizer.transform(df_pqt)\n",
    "\n",
    "df_pqt.select('words').take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Remove the stop words\n",
    "nltk.download('stopwords')\n",
    "stopwords_bc = spark.sparkContext.broadcast(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_text_cleaner(words):\n",
    "    words_clean = []\n",
    "    for a_w in words:\n",
    "        if not a_w in stopwords_bc.value:\n",
    "            words_clean.append(a_w)\n",
    "    \n",
    "    # Return the cleaned words.\n",
    "    return words_clean\n",
    "\n",
    "test_words = ['it', 'is', 'great', 'you', 'have', 'been', 'kitesurfing', 'that', 'long']\n",
    "row_text_cleaner(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row \n",
    "\n",
    "def f(x):\n",
    "    data = x.asDict()\n",
    "    data['wordsclean'] = row_text_cleaner(x.words)\n",
    "    \n",
    "    # The purpose of ** is to give the ability to feed a function's arguments \n",
    "    # by providing a dictionary (e.g. f(**{'x' : 1, 'y' : 2}) ).\n",
    "    return Row(**data)\n",
    "\n",
    "# NOTE:\n",
    "# There is a need to store the result into df_pqt2 otherwise the\n",
    "# added words_clean added column does not show well if we store it in the same df_pqt when running:\n",
    "# df_pqt.select('words_clean').show()\n",
    "rdd_tmp = df_pqt.rdd.map(f)\n",
    "df_pqt = rdd_tmp.toDF()\n",
    "\n",
    "df_pqt.select('wordsclean').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove intermediairy data not needed anymore.\n",
    "df_pqt.printSchema()\n",
    "# df_pqt = df_pqt.withColumnRenamed('words_clean', 'words')\n",
    "df_pqt = df_pqt.drop('textclean')\n",
    "df_pqt.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation of the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HashingTF testing on small vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "sentenceData = spark.createDataFrame([\n",
    "    (0, \"Hi I heard about Spark and I love SPark with Java, I read a lot about java and spark, sparky!\"),\n",
    "    (0, \"I wish Java could use case classes\"),\n",
    "    (1, \"Logistic regression models are neat\")\n",
    "], [\"label\", \"sentence\"])\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(sentenceData)\n",
    "\n",
    "# This uses the hash and the modulo numFeatures to define a bucket where to put a word.\n",
    "# It is efficient as it does not store the vocabulary.\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=5096)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "\n",
    "featurizedData.select('words', 'rawFeatures').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer test on small data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"rawfeatures\", vocabSize=70, minDF=1.0)\n",
    "model = cv.fit(featurizedData)\n",
    "result = model.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.select('rawfeatures', 'words').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF on reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "df_pqt = df_pqt.drop('featurestf')\n",
    "cv = CountVectorizer(inputCol=\"wordsclean\", outputCol=\"featurestf\", vocabSize=30000, minDF=1.0)\n",
    "model_cv = cv.fit(df_pqt)\n",
    "df_pqt = model_cv.transform(df_pqt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique words in the corpus: %s\" % len(model_cv.vocabulary))\n",
    "print(\"Excerpt of the vocabulary\\n\" + str(model_cv.vocabulary[1:100]))\n",
    "\n",
    "# result.select('features').rdd.map(lambda x: print(x)).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pqt.take(1)[0].featurestf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "# Drop the column first.\n",
    "df_pqt = df_pqt.drop('featuresidf')\n",
    "\n",
    "# IDF uses a term frequency vector:\n",
    "# http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=tfidf#pyspark.mllib.feature.IDF\n",
    "idf = IDF(inputCol=\"featurestf\", outputCol=\"featuresidf\")\n",
    "idfModel = idf.fit(df_pqt)\n",
    "df_pqt = idfModel.transform(df_pqt)\n",
    "\n",
    "df_pqt.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_pqt.select('reviewpolarity', \"reviewrating\", \"featuresidf\", 'text').take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a logistic regression for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model using N-fold stratified cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Remove the stop words\n",
    "nltk.download('stopwords')\n",
    "stopwords_set = list(set(stopwords.words('english')))\n",
    "\n",
    "stopwords_set[1:20]\n",
    "# stopwords_bc = spark.sparkContext.broadcast(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "\n",
    "# Create a test df.\n",
    "df0 = transform_html_clean(df_pqt, 'textclean')\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"textclean\", outputCol=\"words_tknz\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"words_test\", stopWords=stopwords_set)\n",
    "pipeline = Pipeline(stages=[tokenizer, remover])\n",
    "\n",
    "len(pipeline.fit(df0).transform(df0).head().words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the df into train and test\n",
    "df_training, df_test = df_pqt.randomSplit([0.9, 0.1], seed=12345)\n",
    "\n",
    "df_training.count(), df_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.groupBy('reviewpolarity').count().show()\n",
    "df_test.groupBy('reviewpolarity').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df_training.drop('words')\n",
    "df_training = df_training.drop('featurestf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator , RegressionEvaluator\n",
    "from pyspark.ml.feature import StopWordsRemover, HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Based on Spark doc\n",
    "# https://spark.apache.org/docs/latest/ml-tuning.html#cross-validation\n",
    "\n",
    "# Define the stages.\n",
    "tokenizer = Tokenizer(inputCol=\"textclean\", outputCol=\"words_tknz\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"words\", stopWords=stopwords_set)\n",
    "\n",
    "# The idea is to create a features vector from a list of words.\n",
    "\n",
    "# 1) Use this hashing Term Frequency.\n",
    "hashingTF = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "# Or 2) use the Term Frequency - Inverse Document Frequency.\n",
    "cv = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"featurestf\", vocabSize=30000, minDF=1.0)\n",
    "idf = IDF(inputCol=cv.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "# Create the pipeline.\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, cv, idf, lr])\n",
    "\n",
    "# Define the criteria ranges.\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [100, 50000, 200000]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "# The evaluator of each models.\n",
    "# evaluator = RegressionEvaluator(metricName=\"r2\")\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "# Define the cross validation runner.\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=5)  # use 3+ folds in practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "df_training_tmp = df_training.withColumnRenamed('reviewpolarity', 'label')\n",
    "df_training_ppl = transform_html_clean(df_training_tmp, 'textclean')\n",
    "\n",
    "# Train the model.\n",
    "cvModel = crossval.fit(df_training_ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_pip = model_best.transform(df_training_ppl)\n",
    "eval_val = evaluator.evaluate(df_training_pip)\n",
    "print(evaluator.isLargerBetter())\n",
    "print(eval_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_pip.filter(df_training_pip.label == df_training_pip.prediction) \\\n",
    "    .select('label', 'probability', 'prediction', 'words').take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the cross validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop('featurestf')\n",
    "df_test = df_test.drop('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data.\n",
    "df_test_tmp = df_test.withColumnRenamed('reviewpolarity','label')\n",
    "df_test_ppl = transform_html_clean(df_test_tmp, 'textclean')\n",
    "\n",
    "# Make prediction.\n",
    "df_test_res = model_best.transform(df_test_ppl)\n",
    "df_test_res.select('probability', 'label','prediction', 'features', 'words').take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluator.evaluate(df_test_res))\n",
    "# df_test_res.filter(df_test_res.label == df_test_res.prediction) \\\n",
    "#     .select('label', 'probability', 'prediction', 'features', 'words').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "rdd_training_pip = df_training_pip.select('prediction', 'label').rdd.map(lambda row: (row[0], float(row[1])))\n",
    "rdd_training_pip.take(2)\n",
    "\n",
    "# print(rdd_training_pip.toDF().toPandas().shape)\n",
    "\n",
    "metrics = MulticlassMetrics(rdd_training_pip)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print()\n",
    "print(metrics.truePositiveRate(1.0))\n",
    "print(metrics.falsePositiveRate(1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receiver Operating Characteristics (ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel.bestModel.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionSummary\n",
    "\n",
    "# Get the Logistic regression model to get the summary.\n",
    "summary = cvModel.bestModel.stages[-1].summary\n",
    "summary.roc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# As defined by IPython matplotlib kernel\n",
    "# https://ipython.readthedocs.io/en/stable/interactive/plotting.html#id1\n",
    "%matplotlib inline\n",
    "\n",
    "aPlt = summary.roc.toPandas().plot(x='FPR', y='TPR', colormap='winter_r')\n",
    "plt.plot([0.0, 1.0], [0.0, 1.0], linestyle='--', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent for online and out-of-core learning Using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the df_csv loaded earlier.\n",
    "print(\"%s entries from the CSV file\" % df_csv.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a generator to load the data from the file simulating a streaming.\n",
    "ttl = 100000\n",
    "file_csv = os.path.join(base_path, (\"aclImdb_%s.csv\" % ttl))\n",
    "\n",
    "def stream_doc():\n",
    "    with open(file_csv, 'r', encoding='utf-8') as csv:\n",
    "        # skip header.\n",
    "        next(csv)\n",
    "        \n",
    "        for line in csv:\n",
    "            cells = line.split(',')\n",
    "#             datasettype,filename,datetimecreated,reviewid,reviewpolarity,reviewrating,text = cells[0], \\\n",
    "#             cells[1], cells[2], cells[3], cells[4], cells[5], \",\".join(cells[6:]).strip()\n",
    "\n",
    "            filename,reviewpolarity,text = cells[1], cells[4], \",\".join(cells[6:]).strip()\n",
    "\n",
    "            yield filename,reviewpolarity,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = stream_doc()\n",
    "print(next(generator))\n",
    "print(next(generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns a number of documents (id, text) and their label from the doc stream.\n",
    "def get_mini_batch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            filename,reviewpolarity,text = next(doc_stream)\n",
    "            docs.append([filename, text])\n",
    "            y.append(int(reviewpolarity))\n",
    "    except StopIteration:\n",
    "        return docs, y\n",
    "    \n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the function we just wrote.\n",
    "get_mini_batch(stream_doc(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of SciKit Learn data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "# from scipy.sparse.csr import csr_matrix\n",
    "\n",
    "boston = load_boston()\n",
    "print(type(boston.data[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline.\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression \n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator , RegressionEvaluator\n",
    "from pyspark.ml.feature import StopWordsRemover, HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Define the stages.\n",
    "tokenizer = Tokenizer(inputCol=\"textclean\", outputCol=\"words_tknz\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"words\", stopWords=stopwords_set)\n",
    "\n",
    "# The idea is to create a features vector from a list of words.\n",
    "\n",
    "# 1) Use this hashing Term Frequency.\n",
    "hashingTF = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "# Create the pipeline.\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF])\n",
    "\n",
    "# The evaluator of each models.\n",
    "# evaluator = RegressionEvaluator(metricName=\"r2\")\n",
    "evaluator = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent Using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "\n",
    "clf = SGDClassifier(loss=\"log\", penalty=\"l2\", max_iter=5, shuffle=True)\n",
    "\n",
    "# Get the X and y labels.\n",
    "def generate_X_y_labels(size):\n",
    "    data_batch, labels_batch = get_mini_batch(data_stream, size)\n",
    "    \n",
    "    if not data_batch: return np.empty(), np.empty()\n",
    "    \n",
    "    df_batch = spark.createDataFrame(data_batch, ('id', 'text'))\n",
    "\n",
    "    # Data cleansing.\n",
    "    df_batch_clean = transform_html_clean(df_batch, 'textclean')\n",
    "    df_training_tmp = df_batch_clean.withColumnRenamed('reviewpolarity', 'label')\n",
    "\n",
    "    # Run the tokenizer and remover pipeline.\n",
    "    m_pip = pipeline.fit(df_training_tmp)\n",
    "    df_pip_batch = m_pip.transform(df_training_tmp)\n",
    "    # Update the SGD regression weights.\n",
    "\n",
    "    # Let's get the right shape for the SparseVector data into numpy arrays.\n",
    "    series = df_pip_batch.toPandas()['features'].apply(lambda x : np.array(x.toArray())).as_matrix().reshape(-1,1)\n",
    "    X = np.apply_along_axis(lambda x : x[0], 1, series)\n",
    "    y_labels =  np.array(labels_batch)\n",
    "\n",
    "    return X, y_labels\n",
    "\n",
    "classes = np.array([0, 1])\n",
    "\n",
    "# print(X[:])\n",
    "# print(y_labels[1:10])\n",
    "\n",
    "# Simulating a streaming\n",
    "data_stream = stream_doc()\n",
    "\n",
    "# Train the 45000 data from the entire data set.\n",
    "for i in range(4):\n",
    "    print(\"range %i\" % i)\n",
    "    X_train, y_labels_train = generate_X_y_labels(1000)\n",
    "    if not len(X_train): break\n",
    "        \n",
    "    model_sgd = clf.partial_fit(X_train, y_labels_train, classes=classes)\n",
    "\n",
    "# Test on the last 5000 entries.\n",
    "X_test, y_labels_test = generate_X_y_labels(5000)\n",
    "\n",
    "print(X_test)\n",
    "if len(X_test):\n",
    "    print(\"\\nscore: %.3f\" % model_sgd.score(X_test, y_labels_test))\n",
    "else:\n",
    "    print('No data')\n",
    "\n",
    "# Train the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark V2.3.2 (Local)",
   "language": "python",
   "name": "pyspark-2.3.2-local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
