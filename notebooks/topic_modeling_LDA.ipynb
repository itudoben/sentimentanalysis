{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling using Latent Dirichlet Allocation (Clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook is using [Stanford IMDb Review dataset](http://ai.stanford.edu/~amaas/data/sentiment \"Stanford IMDb Large Movie Review Dataset\").\n",
    "One must download it, install it locally and set up the variable 'base_path' below to point to the FS path of the dataset.\n",
    "\n",
    "This notebook is about topic modeling using a technique called Latent Dirichlet Allocation (LDA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['README', 'aclImdb_100000.csv', 'aclImdb_100000_raw.parquet', 'aclImdb_10000_raw.parquet', 'aclImdb_1000_raw.parquet', 'aclImdb_100_raw.parquet', 'aclImdb_20000_raw.parquet', 'aclImdb_2000_raw.parquet', 'aclImdb_200_raw.parquet', 'aclImdb_210_raw.parquet', 'aclImdb_211_raw.parquet', 'aclImdb_250.csv', 'aclImdb_250_raw.parquet', 'aclImdb_251_raw.parquet', 'aclImdb_252_raw.parquet', 'aclImdb_300_raw.parquet', 'aclImdb_301_raw.parquet', 'aclImdb_50000_raw.parquet', 'imdb.vocab', 'imdbEr.txt', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "# Set the base of the data path where folders test/neg, train/pos, etc, live.\n",
    "base_path = \"../../data/aclImdb\" # Change this here to the right path.\n",
    "\n",
    "# The folders where to look for the reviews.\n",
    "data_sets = ['test', 'train']\n",
    "sa_dir_names = ['neg', 'pos']\n",
    "\n",
    "# List the content of the data path for the sake of checking the data set folders.\n",
    "files = !ls {base_path}\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "LDA works on numbers and not on text. The data has to be converted into a feature vector representation for LDA to be able to compute metrics. The metrics will then serve to define clusters and group observations together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Python system path to find our modules.\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import our modules.\n",
    "import file_loader as fl\n",
    "\n",
    "# Add the file to SparkContext for the executor to find it.\n",
    "sc.addPyFile('../src/file_loader.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of observations.\n",
    "obs_nb = 1000\n",
    "\n",
    "# Load the data in a parquet file.\n",
    "file_parquet, _ = fl.load_data(base_path, obs_nb, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m../../data/aclImdb/aclImdb_100000_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_10000_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_1000_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_100_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_20000_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_2000_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_200_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_210_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_211_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_250_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_251_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_252_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_300_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_301_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_50000_raw.parquet\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -d {base_path}/*.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/aclImdb/aclImdb_1000_raw.parquet'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------------+--------+--------------+------------+--------------------+\n",
      "|datasettype|   filename| datetimecreated|reviewid|reviewpolarity|reviewrating|                text|\n",
      "+-----------+-----------+----------------+--------+--------------+------------+--------------------+\n",
      "|       test| 3515_8.txt|20181026T091736Z|    3515|             1|           8|I didn't have ver...|\n",
      "|       test|2823_10.txt|20181026T091736Z|    2823|             1|          10|This movie makes ...|\n",
      "|       test| 4278_9.txt|20181026T091736Z|    4278|             1|           9|I have to admit I...|\n",
      "|       test|5651_10.txt|20181026T091736Z|    5651|             1|          10|This film is a kn...|\n",
      "|       test|4366_10.txt|20181026T091736Z|    4366|             1|          10|Yes, this movie w...|\n",
      "|       test|5100_10.txt|20181026T091736Z|    5100|             1|          10|I first saw this ...|\n",
      "|       test|12123_7.txt|20181026T091736Z|   12123|             1|           7|I don't know if i...|\n",
      "|       test| 5005_8.txt|20181026T091736Z|    5005|             1|           8|Talkshow with Spi...|\n",
      "|       test|4780_10.txt|20181026T091736Z|    4780|             1|          10|This was the firs...|\n",
      "|       test| 2515_8.txt|20181026T091736Z|    2515|             1|           8|In 1937 Darryl Za...|\n",
      "|       test|10684_7.txt|20181026T091736Z|   10684|             1|           7|Interesting premi...|\n",
      "|       test| 2987_8.txt|20181026T091736Z|    2987|             1|           8|Most of these rev...|\n",
      "|       test|5751_10.txt|20181026T091736Z|    5751|             1|          10|I can't even begi...|\n",
      "|       test|4266_10.txt|20181026T091736Z|    4266|             1|          10|This is a film th...|\n",
      "|       test| 5040_8.txt|20181026T091736Z|    5040|             1|           8|Possibly the best...|\n",
      "|       test|4537_10.txt|20181026T091736Z|    4537|             1|          10|For only doing a ...|\n",
      "|       test|10210_7.txt|20181026T091736Z|   10210|             1|           7|While escaping fr...|\n",
      "|       test|5000_10.txt|20181026T091736Z|    5000|             1|          10|And what is its g...|\n",
      "|       test| 2806_9.txt|20181026T091736Z|    2806|             1|           9|I have to say tha...|\n",
      "|       test|4895_10.txt|20181026T091736Z|    4895|             1|          10|I have to admit t...|\n",
      "+-----------+-----------+----------------+--------+--------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the parquet file into a data frame.\n",
    "df_pqt = spark.read.parquet(file_parquet)\n",
    "\n",
    "# Showing some observations (entries).\n",
    "df_pqt.persist()\n",
    "df_pqt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/hujol/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"you'd\",\n",
       " 'down',\n",
       " 'needn',\n",
       " \"mustn't\",\n",
       " 'hers',\n",
       " 'against',\n",
       " 'your',\n",
       " 'through',\n",
       " 'further',\n",
       " 'once']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Remove the stop words\n",
    "nltk.download('stopwords')\n",
    "stopwords_set = list(set(stopwords.words('english')))\n",
    "\n",
    "stopwords_set[:10]\n",
    "# stopwords_bc = spark.sparkContext.broadcast(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "\n",
    "# Remove all HTML tags.\n",
    "html_tags_remover = fl.HTMLTagsRemover(inputCol='text', outputCol='textclean')\n",
    "\n",
    "# Tokenize and remove stop words.\n",
    "tokenizer = Tokenizer(inputCol=html_tags_remover.getOutputCol(), outputCol=\"words_tknz\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"words\", \n",
    "                           stopWords=stopwords_set)\n",
    "\n",
    "# Create the pipeline.\n",
    "pipeline_cleaner = Pipeline(stages=[html_tags_remover, tokenizer, remover])\n",
    "\n",
    "# Fit the pipeline.\n",
    "model_p = pipeline_cleaner.fit(df_pqt)\n",
    "\n",
    "# Tranform the data frame.\n",
    "df_cleaned = model_p.transform(df_pqt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647 rs of this film are Laurence Harvey and Julie Harris. Now before this film, I'd only see Miss Harris in East of Eden with James Dean and I own an audio tape of The Glass Menagerie that she did on stage with Monty Clift and Jessica Tandy, so I wasn't sure how she'd be in this role and BOY, did she impress me. How hammy was she? I love ham! ;-) Mr. H\n",
      "1630 rs of this film are Laurence Harvey and Julie Harris. Now before this film, I'd only see Miss Harris in East of Eden with James Dean and I own an audio tape of The Glass Menagerie that she did on stage with Monty Clift and Jessica Tandy, so I wasn't sure how she'd be in this role and BOY, did she impress me. How hammy was she? I love ham! ;- Mr. Ha\n",
      "156 ['yes,', 'movie', 'hilarious', 'acting', 'top', 'notch', 'whole', 'cast.', 'except', 'shelley']\n"
     ]
    }
   ],
   "source": [
    "# Check the resulting transformation.\n",
    "len(df_cleaned.head().words)\n",
    "a_sample = df_cleaned.take(5)[4]\n",
    "print(len(a_sample['text']), a_sample['text'][250:600])\n",
    "print(len(a_sample['textclean']), a_sample['textclean'][250:600])\n",
    "print(len(a_sample['words']), a_sample['words'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(905, 95)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the df into train and test\n",
    "df_p_training, df_p_test = df_cleaned.randomSplit([0.9, 0.1], seed=12345)\n",
    "\n",
    "df_p_training.count(), df_p_test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a features vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "\n",
    "df_p_training = df_p_training.drop('featurestf')\n",
    "\n",
    "# Define the count vector so the IDF can compute the features vector.\n",
    "cv = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"featurestf\", vocabSize=30000, minDF=1.0)\n",
    "idf = IDF(inputCol=cv.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "# Create the pipeline.\n",
    "pipeline = Pipeline(stages=[cv, idf])\n",
    "\n",
    "# Fit the pipeline.\n",
    "model_idf = pipeline.fit(df_p_training)\n",
    "\n",
    "# Transform the data frame.\n",
    "df_idf = model_idf.transform(df_p_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28020, {2: 0.6844, 7: 1.1959, 9: 1.8891, 16: 1.4667, 35: 1.8462, 37: 1.8051, 42: 1.7852, 55: 1.9038, 82: 2.3431, 96: 2.3317, 126: 2.4396, 152: 5.3963, 159: 5.3963, 173: 2.5895, 178: 2.6502, 181: 2.9589, 199: 2.8017, 227: 2.9378, 242: 2.9589, 255: 2.9172, 272: 3.0714, 290: 6.8157, 293: 3.0478, 586: 3.5132, 588: 3.631, 602: 3.5132, 615: 3.5902, 645: 3.631, 664: 3.631, 688: 3.7645, 782: 3.8133, 800: 4.101, 905: 4.0365, 940: 3.9187, 1117: 4.101, 1274: 4.4111, 1285: 8.4882, 1416: 4.4111, 1585: 4.5065, 1633: 4.5065, 1789: 4.5065, 1796: 4.7296, 1822: 4.6118, 2845: 4.8631, 2925: 4.8631, 3198: 5.0173, 3336: 5.0173, 3439: 5.0173, 3450: 5.0173, 3492: 5.0173, 3619: 5.0173, 3642: 5.0173, 3750: 5.1996, 3782: 5.1996, 3797: 5.4227, 4461: 5.1996, 4685: 5.4227, 4825: 18.3477, 5401: 5.4227, 5461: 5.4227, 6641: 12.2318, 6723: 5.7104, 6926: 5.7104, 7450: 5.7104, 8715: 5.7104, 9393: 5.7104, 9552: 5.7104, 10211: 6.1159, 12322: 6.1159, 13475: 6.1159, 17190: 6.1159, 17227: 6.1159, 21756: 6.1159, 25390: 6.1159, 25574: 6.1159, 25806: 6.1159, 26323: 6.1159, 26492: 6.1159, 27810: 6.1159})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result.\n",
    "a_sample = df_idf.take(1)[0]\n",
    "a_sample['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "lda = LDA(k=5, seed=1, optimizer=\"em\")\n",
    "model_lda = lda.fit(df_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28020"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result.\n",
    "model_lda.vocabSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>termIndices</th>\n",
       "      <th>termWeights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 0, 2, 9, 787, 27, 12, 23, 7]</td>\n",
       "      <td>[0.0022201148561984247, 0.0014447574195974062,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0, 3, 15, 21, 344, 48, 14, 2, 4]</td>\n",
       "      <td>[0.0017325556461041337, 0.0014006685968434127,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[9, 1, 0, 4, 2, 5, 37, 18, 95, 11]</td>\n",
       "      <td>[0.0021506657295716843, 0.0016757227399249817,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 0, 9, 145, 7, 6, 3, 2, 23, 10]</td>\n",
       "      <td>[0.0018550225680454926, 0.0018344894985548024,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 9, 3, 1, 8, 7, 5, 13, 87, 2]</td>\n",
       "      <td>[0.0020106356340426285, 0.0019638129275122364,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                           termIndices  \\\n",
       "0      0   [1, 3, 0, 2, 9, 787, 27, 12, 23, 7]   \n",
       "1      1  [1, 0, 3, 15, 21, 344, 48, 14, 2, 4]   \n",
       "2      2    [9, 1, 0, 4, 2, 5, 37, 18, 95, 11]   \n",
       "3      3    [1, 0, 9, 145, 7, 6, 3, 2, 23, 10]   \n",
       "4      4      [0, 9, 3, 1, 8, 7, 5, 13, 87, 2]   \n",
       "\n",
       "                                         termWeights  \n",
       "0  [0.0022201148561984247, 0.0014447574195974062,...  \n",
       "1  [0.0017325556461041337, 0.0014006685968434127,...  \n",
       "2  [0.0021506657295716843, 0.0016757227399249817,...  \n",
       "3  [0.0018550225680454926, 0.0018344894985548024,...  \n",
       "4  [0.0020106356340426285, 0.0019638129275122364,...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lda.describeTopics().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_matrix = model_lda.topicsMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[121.78837608, 123.37933398, 130.1902185 , 162.13468156,\n",
       "        184.70223993],\n",
       "       [190.6509602 , 152.61394607, 144.86314676, 163.94942222,\n",
       "        150.35010131],\n",
       "       [110.38035744, 102.92382594, 112.34209082, 105.37327057,\n",
       "        109.6216282 ],\n",
       "       [124.06763035, 116.58349022,  95.88234195, 106.20637297,\n",
       "        173.60047713],\n",
       "       [ 75.35353221, 102.25215346, 123.31206116,  81.31305096,\n",
       "        109.23356727],\n",
       "       [ 92.27207712,  89.30318714, 108.73439725,  79.46784329,\n",
       "        127.98197917],\n",
       "       [ 97.75653344,  87.62623873,  73.11879014, 106.80084342,\n",
       "        109.29810297],\n",
       "       [101.69432469,  71.3374006 ,  90.28007237, 108.40931056,\n",
       "        128.16977323],\n",
       "       [ 71.35872522,  97.7858671 ,  73.36306366,  83.20950862,\n",
       "        131.27991479],\n",
       "       [105.24280858,  67.51132737, 185.9210941 , 114.53798567,\n",
       "        180.40098383]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_matrix.toArray()[:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv = cv.fit(df_p_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie', 'film', 'one', 'like', 'good', 'would', 'even', 'really', 'see', '-', 'get', 'great', 'story', 'time', 'much', 'first', 'think', 'make', 'also', 'people']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model_cv.vocabulary[:20])\n",
    "'it' in stopwords_set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark V2.3.2 (Local)",
   "language": "python",
   "name": "pyspark-2.3.2-local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
