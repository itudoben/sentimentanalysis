{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling using Latent Dirichlet Allocation (Clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook is using [Stanford IMDb Review dataset](http://ai.stanford.edu/~amaas/data/sentiment \"Stanford IMDb Large Movie Review Dataset\").\n",
    "One must download it, install it locally and set up the variable 'base_path' below to point to the FS path of the dataset.\n",
    "\n",
    "This notebook is about topic modeling using a technique called Latent Dirichlet Allocation (LDA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['README', 'aclImdb_100000.csv', 'aclImdb_100000_raw.parquet', 'aclImdb_10000_raw.parquet', 'aclImdb_1000_raw.parquet', 'aclImdb_100_raw.parquet', 'aclImdb_20000_raw.parquet', 'aclImdb_2000_raw.parquet', 'aclImdb_200_raw.parquet', 'aclImdb_210_raw.parquet', 'aclImdb_211_raw.parquet', 'aclImdb_250.csv', 'aclImdb_250_raw.parquet', 'aclImdb_251_raw.parquet', 'aclImdb_252_raw.parquet', 'aclImdb_300_raw.parquet', 'aclImdb_301_raw.parquet', 'aclImdb_50000_raw.parquet', 'imdb.vocab', 'imdbEr.txt', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "# Set the base of the data path where folders test/neg, train/pos, etc, live.\n",
    "base_path = \"../../data/aclImdb\" # Change this here to the right path.\n",
    "\n",
    "# The folders where to look for the reviews.\n",
    "data_sets = ['test', 'train']\n",
    "sa_dir_names = ['neg', 'pos']\n",
    "\n",
    "# List the content of the data path for the sake of checking the data set folders.\n",
    "files = !ls {base_path}\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "LDA works on numbers and not on text. The data has to be converted into a feature vector representation for LDA to be able to compute metrics. The metrics will then serve to define clusters and group observations together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Python system path to find our modules.\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import our modules.\n",
    "import file_loader as fl\n",
    "\n",
    "# Add the file to SparkContext for the executor to find it.\n",
    "sc.addPyFile('../src/file_loader.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of observations.\n",
    "obs_nb = 1000\n",
    "\n",
    "# Load the data in a parquet file.\n",
    "file_parquet, _ = fl.load_data(base_path, obs_nb, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m../../data/aclImdb/aclImdb_100000_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_10000_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_1000_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_100_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_20000_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_2000_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_200_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_210_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_211_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_250_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_251_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_252_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_300_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_301_raw.parquet\u001b[m\u001b[m\n",
      "\u001b[34m../../data/aclImdb/aclImdb_50000_raw.parquet\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -d {base_path}/*.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/aclImdb/aclImdb_1000_raw.parquet'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------------+--------+--------------+------------+--------------------+\n",
      "|datasettype|   filename| datetimecreated|reviewid|reviewpolarity|reviewrating|                text|\n",
      "+-----------+-----------+----------------+--------+--------------+------------+--------------------+\n",
      "|       test| 3515_8.txt|20181026T102204Z|    3515|             1|           8|I didn't have ver...|\n",
      "|       test|2823_10.txt|20181026T102204Z|    2823|             1|          10|This movie makes ...|\n",
      "|       test| 4278_9.txt|20181026T102204Z|    4278|             1|           9|I have to admit I...|\n",
      "|       test|5651_10.txt|20181026T102204Z|    5651|             1|          10|This film is a kn...|\n",
      "|       test|4366_10.txt|20181026T102204Z|    4366|             1|          10|Yes, this movie w...|\n",
      "|       test|5100_10.txt|20181026T102204Z|    5100|             1|          10|I first saw this ...|\n",
      "|       test|12123_7.txt|20181026T102204Z|   12123|             1|           7|I don't know if i...|\n",
      "|       test| 5005_8.txt|20181026T102204Z|    5005|             1|           8|Talkshow with Spi...|\n",
      "|       test|4780_10.txt|20181026T102204Z|    4780|             1|          10|This was the firs...|\n",
      "|       test| 2515_8.txt|20181026T102204Z|    2515|             1|           8|In 1937 Darryl Za...|\n",
      "|       test|10684_7.txt|20181026T102204Z|   10684|             1|           7|Interesting premi...|\n",
      "|       test| 2987_8.txt|20181026T102204Z|    2987|             1|           8|Most of these rev...|\n",
      "|       test|5751_10.txt|20181026T102204Z|    5751|             1|          10|I can't even begi...|\n",
      "|       test|4266_10.txt|20181026T102204Z|    4266|             1|          10|This is a film th...|\n",
      "|       test| 5040_8.txt|20181026T102204Z|    5040|             1|           8|Possibly the best...|\n",
      "|       test|4537_10.txt|20181026T102204Z|    4537|             1|          10|For only doing a ...|\n",
      "|       test|10210_7.txt|20181026T102204Z|   10210|             1|           7|While escaping fr...|\n",
      "|       test|5000_10.txt|20181026T102204Z|    5000|             1|          10|And what is its g...|\n",
      "|       test| 2806_9.txt|20181026T102204Z|    2806|             1|           9|I have to say tha...|\n",
      "|       test|4895_10.txt|20181026T102204Z|    4895|             1|          10|I have to admit t...|\n",
      "+-----------+-----------+----------------+--------+--------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the parquet file into a data frame.\n",
    "df_pqt = spark.read.parquet(file_parquet)\n",
    "\n",
    "# Showing some observations (entries).\n",
    "df_pqt.persist()\n",
    "df_pqt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/hujol/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Remove the stop words\n",
    "nltk.download('stopwords')\n",
    "stopwords_set = list(set(stopwords.words('english')))\n",
    "\n",
    "stopwords_set[:10]\n",
    "# stopwords_bc = spark.sparkContext.broadcast(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrich the Stop Words List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_set += ['-', '&', 'i\\'m', '2', 'one', 'two', '.', 'can\\'t', 'i\\'ve']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "\n",
    "# Remove all HTML tags.\n",
    "html_tags_remover = fl.HTMLTagsRemover(inputCol='text', outputCol='textclean')\n",
    "\n",
    "# Tokenize and remove stop words.\n",
    "tokenizer = Tokenizer(inputCol=html_tags_remover.getOutputCol(), outputCol=\"words_tknz\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"words\", \n",
    "                           stopWords=stopwords_set)\n",
    "\n",
    "# Create the pipeline.\n",
    "pipeline_cleaner = Pipeline(stages=[html_tags_remover, tokenizer, remover])\n",
    "\n",
    "# Fit the pipeline.\n",
    "model_p = pipeline_cleaner.fit(df_pqt)\n",
    "\n",
    "# Tranform the data frame.\n",
    "df_cleaned = model_p.transform(df_pqt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647 rs of this film are Laurence Harvey and Julie Harris. Now before this film, I'd only see Miss Harris in East of Eden with James Dean and I own an audio tape of The Glass Menagerie that she did on stage with Monty Clift and Jessica Tandy, so I wasn't sure how she'd be in this role and BOY, did she impress me. How hammy was she? I love ham! ;-) Mr. H\n",
      "1630 rs of this film are Laurence Harvey and Julie Harris. Now before this film, I'd only see Miss Harris in East of Eden with James Dean and I own an audio tape of The Glass Menagerie that she did on stage with Monty Clift and Jessica Tandy, so I wasn't sure how she'd be in this role and BOY, did she impress me. How hammy was she? I love ham! ;- Mr. Ha\n",
      "152 ['yes,', 'movie', 'hilarious', 'acting', 'top', 'notch', 'whole', 'cast.', 'except', 'shelley']\n"
     ]
    }
   ],
   "source": [
    "# Check the resulting transformation.\n",
    "len(df_cleaned.head().words)\n",
    "a_sample = df_cleaned.take(5)[4]\n",
    "print(len(a_sample['text']), a_sample['text'][250:600])\n",
    "print(len(a_sample['textclean']), a_sample['textclean'][250:600])\n",
    "print(len(a_sample['words']), a_sample['words'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(905, 95)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the df into train and test\n",
    "df_p_training, df_p_test = df_cleaned.randomSplit([0.9, 0.1], seed=12345)\n",
    "\n",
    "df_p_training.count(), df_p_test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a features vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "\n",
    "df_p_training = df_p_training.drop('featurestf')\n",
    "\n",
    "# Define the count vector so the IDF can compute the features vector.\n",
    "cv = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"featurestf\", vocabSize=30000, minDF=1.0)\n",
    "idf = IDF(inputCol=cv.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "# Create the pipeline.\n",
    "pipeline = Pipeline(stages=[cv, idf])\n",
    "\n",
    "# Fit the pipeline.\n",
    "model_idf = pipeline.fit(df_p_training)\n",
    "\n",
    "# Transform the data frame that was cleaning by the pipeline_cleaner.\n",
    "df_idf = model_idf.transform(df_p_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(28011, {6: 1.1959, 14: 1.4667, 32: 1.8462, 34: 1.8051, 39: 1.7852, 51: 1.9038, 77: 2.3431, 90: 2.3317, 118: 2.4396, 146: 5.3963, 155: 5.3963, 166: 2.5895, 170: 2.6502, 171: 2.9589, 191: 2.8017, 218: 2.9378, 233: 2.9589, 246: 2.9172, 264: 3.0714, 279: 6.8157, 288: 3.0478, 568: 3.631, 573: 3.5132, 588: 3.5132, 610: 3.5902, 635: 3.631, 654: 3.631, 687: 3.7645, 769: 3.8133, 810: 4.101, 893: 4.0365, 929: 3.9187, 1112: 4.101, 1235: 4.4111, 1260: 8.4882, 1433: 4.4111, 1507: 4.5065, 1612: 4.5065, 1759: 4.6118, 1839: 4.5065, 1845: 4.7296, 2663: 4.8631, 2937: 4.8631, 3003: 5.0173, 3074: 5.0173, 3295: 5.0173, 3357: 5.0173, 3402: 5.0173, 3411: 5.0173, 3594: 5.0173, 3676: 5.4227, 4104: 5.1996, 4130: 5.1996, 4445: 5.1996, 5091: 5.4227, 5236: 18.3477, 5424: 5.4227, 5502: 5.4227, 6566: 5.7104, 6949: 12.2318, 8737: 5.7104, 9072: 5.7104, 9318: 5.7104, 9622: 5.7104, 9958: 5.7104, 10086: 6.1159, 10808: 6.1159, 11210: 6.1159, 14057: 6.1159, 15814: 6.1159, 16998: 6.1159, 20354: 6.1159, 20572: 6.1159, 22582: 6.1159, 22995: 6.1159, 23028: 6.1159, 27896: 6.1159})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result.\n",
    "a_sample = df_idf.take(1)[0]\n",
    "a_sample['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "lda = LDA(k=5, seed=1, optimizer=\"em\")\n",
    "model_lda = lda.fit(df_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28011"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Check the result.\n",
    "model_lda.vocabSize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics Found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>termIndices</th>\n",
       "      <th>termWeights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 4, 207, 0, 6, 13, 10, 11, 12]</td>\n",
       "      <td>[0.002003425392168439, 0.0014707285271285076, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0, 3, 5, 12, 82, 18, 10, 8, 6]</td>\n",
       "      <td>[0.0018693115981087355, 0.001570741148537871, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0, 2, 4, 52, 17, 18, 9, 23, 33]</td>\n",
       "      <td>[0.0017917824315858437, 0.001779742523937128, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 0, 44, 2, 13, 7, 14, 25, 31, 49]</td>\n",
       "      <td>[0.0016817130608839928, 0.001667629490558416, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1, 2, 3, 14, 6, 21, 20, 8, 777]</td>\n",
       "      <td>[0.0019845099274118905, 0.00181662420598082, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                           termIndices  \\\n",
       "0      0  [1, 2, 4, 207, 0, 6, 13, 10, 11, 12]   \n",
       "1      1    [1, 0, 3, 5, 12, 82, 18, 10, 8, 6]   \n",
       "2      2   [1, 0, 2, 4, 52, 17, 18, 9, 23, 33]   \n",
       "3      3  [1, 0, 44, 2, 13, 7, 14, 25, 31, 49]   \n",
       "4      4   [0, 1, 2, 3, 14, 6, 21, 20, 8, 777]   \n",
       "\n",
       "                                         termWeights  \n",
       "0  [0.002003425392168439, 0.0014707285271285076, ...  \n",
       "1  [0.0018693115981087355, 0.001570741148537871, ...  \n",
       "2  [0.0017917824315858437, 0.001779742523937128, ...  \n",
       "3  [0.0016817130608839928, 0.001667629490558416, ...  \n",
       "4  [0.0019845099274118905, 0.00181662420598082, 0...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_info = model_lda.describeTopics().toPandas()\n",
    "topics_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_matrix = model_lda.topicsMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109.64332199, 132.70762858, 163.25540536, 140.43941247,\n",
       "        176.14908165],\n",
       "       [177.26205424, 157.93303021, 164.35982355, 141.6254603 ,\n",
       "        161.24720827],\n",
       "       [130.12930801,  99.80417035, 129.80960645, 123.08570722,\n",
       "        133.51152058],\n",
       "       [ 82.85808233, 116.79360372, 100.21672657,  64.47604241,\n",
       "        127.11991003],\n",
       "       [124.48142814,  75.54921523, 114.48371413,  78.10292185,\n",
       "        105.14220462],\n",
       "       [ 83.84125523, 113.27301487,  89.83652336,  87.33993819,\n",
       "        100.30977706],\n",
       "       [103.57355513,  99.96773992,  87.58418959,  94.33253502,\n",
       "        114.43286178],\n",
       "       [ 70.37627816,  88.5766793 ,  95.90784817,  99.74589052,\n",
       "        102.39038325],\n",
       "       [ 90.40969962, 101.15412813,  78.50702074,  80.17414352,\n",
       "        105.59311164],\n",
       "       [ 79.42631087,  97.32157873, 109.04295968,  86.51586956,\n",
       "         81.41165087]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the topic matrix.\n",
    "topics_matrix.toArray()[:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the CountVectorizer model to fit the cleaned data frame and get the vocabulary.\n",
    "model_cv = cv.fit(df_p_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie', 'film', 'like', 'good', 'would', 'even', 'really', 'see', 'get', 'great', 'story', 'time', 'much', 'first', 'think', 'make', 'also', 'people', 'could', 'never', 'many', 'watch', 'it.', 'bad', 'way', 'made', 'know', 'movies', 'well', 'characters', 'movie.', 'ever', 'character', 'still', 'little', 'say', 'best', 'plot', 'love', 'film.', 'seen', 'films', 'go', 'something', 'show', 'acting', 'real', 'going', 'better', 'watching', 'look', 'nothing', 'old', 'film,', 'movie,', 'every', 'back', 'man', 'makes', 'actually', 'scene', 'quite', 'actors', 'want', 'lot', 'find', 'saw', 'thing', 'scenes', 'without', 'may', 'part', 'life', 'end', 'give', 'years', 'take', 'seems', 'around', 'another', 'pretty', 'things', 'funny', 'always', 'come', 'thought', 'music', 'bit', 'us', 'played', 'gets', 'kind', \"he's\", 'probably', 'new', 'feel', 'director', 'whole', 'almost', 'big', 'work', 'young', 'it,', \"that's\", 'must', 'long', '\"the', 'anything', 'might', 'since', 'main', 'enough', \"there's\", 'far', 'done', 'though', 'however,', 'yet', 'cast', 'trying', 'point', 'fact', 'least', 'world', 'interesting', 'got', 'hard', 'comedy', 'looking', 'someone', 'believe', 'right', 'last', 'horror', 'worst', 'action', 'away', 'original', 'worth', 'sure', 'especially', 'put', 'guy', 'different', 'everything', 'high', 'three', 'american', 'making', 'looks', 'time.', 'script', 'getting', 'special', 'tv', 'seem', 'times', 'simply', 'found', 'seeing', 'sense', 'minutes', 'effects', 'watched', 'goes', 'well,', 'reason', 'everyone', 'john', 'anyone', 'actor', 'used', 'shows', 'plays', 'rather', 'series', 'day', 'poor', 'try', 'comes', 'place', 'woman', 'absolutely', 'shot', 'let', 'although', 'fun', 'recommend', 'set', 'second', 'entire', 'remember', 'full', 'use', 'tell', 'job', 'along', 'liked', 'playing', 'role']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model_cv.vocabulary[:200])\n",
    "terms_in_stop_words_list = [a_term for a_term in model_cv.vocabulary if a_term in stopwords_set]\n",
    "len(terms_in_stop_words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the Words per Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: film, like, would, black, movie, really, first, story, time, much\n",
      "Topic 1: film, movie, good, even, much, funny, could, story, get, really\n",
      "Topic 2: film, movie, like, would, old, people, could, great, bad, still\n",
      "Topic 3: film, movie, show, like, first, see, think, made, ever, watching\n",
      "Topic 4: movie, film, like, good, think, really, watch, many, get, cheesy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for index, term_indices, term_weights in np.array(topics_info):\n",
    "    terms = [model_cv.vocabulary[i] for i in term_indices]\n",
    "    word_to_weight = list(zip(terms, term_weights))\n",
    "    \n",
    "    print(\"Topic %i:\" % index, \", \".join(terms), end='\\n')\n",
    "    \n",
    "    term_stop_words = [a_term for a_term in terms if a_term in stopwords_set]\n",
    "    if term_stop_words:\n",
    "        print(\"Terms in stop words list: %s\" % \", \".join(term_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Movies per Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model to the data frame.\n",
    "df_review_topic = model_lda.transform(df_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Topic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributions = df_review_topic.select('topicDistribution').take(1)[0]['topicDistribution'].toArray()\n",
    "[i ==  max(distributions) for i in distributions].index(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "aaa = df_review_topic.rdd.map(lambda row: Row(row, str([i ==  max(row['topicDistribution'].toArray()) for i in row['topicDistribution'].toArray()].index(True))))\n",
    "aaa.toDF().toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark V2.3.2 (Local)",
   "language": "python",
   "name": "pyspark-2.3.2-local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
